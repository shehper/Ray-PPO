{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alishehper/work/RL-algorithms/env/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from distutils.util import strtobool\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from stable_baselines3.common.atari_wrappers import (  # isort:skip\n",
    "    ClipRewardEnv,\n",
    "    EpisodicLifeEnv,\n",
    "    FireResetEnv,\n",
    "    MaxAndSkipEnv,\n",
    "    NoopResetEnv,\n",
    ")\n",
    "\n",
    "# import ray\n",
    "# ray.init(log_to_driver=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    # fmt: off\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument(\"--exp-name\", type=str, default=os.path.basename(__file__).rstrip(\".py\"),\n",
    "    #     help=\"the name of this experiment\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=1,\n",
    "        help=\"seed of the experiment\")\n",
    "    parser.add_argument(\"--torch-deterministic\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
    "        help=\"if toggled, `torch.backends.cudnn.deterministic=False`\")\n",
    "    parser.add_argument(\"--cuda\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
    "        help=\"if toggled, cuda will be enabled by default\")\n",
    "    parser.add_argument(\"--track\", type=lambda x: bool(strtobool(x)), default=False, nargs=\"?\", const=True,\n",
    "        help=\"if toggled, this experiment will be tracked with Weights and Biases\")\n",
    "    parser.add_argument(\"--wandb-project-name\", type=str, default=\"cleanRL\",\n",
    "        help=\"the wandb's project name\")\n",
    "    parser.add_argument(\"--wandb-entity\", type=str, default=None,\n",
    "        help=\"the entity (team) of wandb's project\")\n",
    "    parser.add_argument(\"--capture-video\", type=lambda x: bool(strtobool(x)), default=False, nargs=\"?\", const=True,\n",
    "        help=\"whether to capture videos of the agent performances (check out `videos` folder)\")\n",
    "\n",
    "    # Algorithm specific arguments\n",
    "    parser.add_argument(\"--env-id\", type=str, default=\"BreakoutNoFrameskip-v4\",\n",
    "        help=\"the id of the environment\")\n",
    "    parser.add_argument(\"--total-timesteps\", type=int, default=10000000,\n",
    "        help=\"total timesteps of the experiments\")\n",
    "    parser.add_argument(\"--learning-rate\", type=float, default=2.5e-4,\n",
    "        help=\"the learning rate of the optimizer\")\n",
    "    parser.add_argument(\"--num-envs\", type=int, default=8,\n",
    "        help=\"the number of parallel game environments\")\n",
    "    parser.add_argument(\"--num-steps\", type=int, default=128,\n",
    "        help=\"the number of steps to run in each environment per policy rollout\")\n",
    "    parser.add_argument(\"--anneal-lr\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
    "        help=\"Toggle learning rate annealing for policy and value networks\")\n",
    "    parser.add_argument(\"--gamma\", type=float, default=0.99,\n",
    "        help=\"the discount factor gamma\")\n",
    "    parser.add_argument(\"--gae-lambda\", type=float, default=0.95,\n",
    "        help=\"the lambda for the general advantage estimation\")\n",
    "    parser.add_argument(\"--num-minibatches\", type=int, default=4,\n",
    "        help=\"the number of mini-batches\")\n",
    "    parser.add_argument(\"--update-epochs\", type=int, default=4,\n",
    "        help=\"the K epochs to update the policy\")\n",
    "    parser.add_argument(\"--norm-adv\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
    "        help=\"Toggles advantages normalization\")\n",
    "    parser.add_argument(\"--clip-coef\", type=float, default=0.1,\n",
    "        help=\"the surrogate clipping coefficient\")\n",
    "    parser.add_argument(\"--clip-vloss\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
    "        help=\"Toggles whether or not to use a clipped loss for the value function, as per the paper.\")\n",
    "    parser.add_argument(\"--ent-coef\", type=float, default=0.01,\n",
    "        help=\"coefficient of the entropy\")\n",
    "    parser.add_argument(\"--vf-coef\", type=float, default=0.5,\n",
    "        help=\"coefficient of the value function\")\n",
    "    parser.add_argument(\"--max-grad-norm\", type=float, default=0.5,\n",
    "        help=\"the maximum norm for the gradient clipping\")\n",
    "    parser.add_argument(\"--target-kl\", type=float, default=None,\n",
    "        help=\"the target KL divergence threshold\")\n",
    "    args = parser.parse_args(\"\")\n",
    "    args.batch_size = int(args.num_envs * args.num_steps)\n",
    "    args.minibatch_size = int(args.batch_size // args.num_minibatches)\n",
    "    # fmt: on\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(env_id, seed, idx, capture_video, run_name):\n",
    "    def thunk():\n",
    "        env = gym.make(env_id)\n",
    "        if capture_video:\n",
    "            if idx == 0:\n",
    "                env = gym.wrappers.RecordVideo(env, f\"videos/{run_name}\")\n",
    "        env = NoopResetEnv(env, noop_max=30)\n",
    "        env = MaxAndSkipEnv(env, skip=4)\n",
    "        env = EpisodicLifeEnv(env)\n",
    "        if \"FIRE\" in env.unwrapped.get_action_meanings():\n",
    "            env = FireResetEnv(env)\n",
    "        env = ClipRewardEnv(env)\n",
    "        env = gym.wrappers.ResizeObservation(env, (84, 84))\n",
    "        env = gym.wrappers.GrayScaleObservation(env)\n",
    "        env = gym.wrappers.FrameStack(env, 4)\n",
    "        env.seed(seed)\n",
    "        env.action_space.seed(seed)\n",
    "        env.observation_space.seed(seed)\n",
    "        return env\n",
    "\n",
    "    return thunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_init and Agent\n",
    "def layer_init(layer, std=np.sqrt(2), bias_const=0.0):\n",
    "    torch.nn.init.orthogonal_(layer.weight, std)\n",
    "    torch.nn.init.constant_(layer.bias, bias_const)\n",
    "    return layer\n",
    "\n",
    "class Agent(nn.Module):\n",
    "    #def __init__(self, obs_space_shape, action_space_n):\n",
    "    def __init__(self, action_space_n):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            layer_init(nn.Conv2d(4, 32, 8, stride=4)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Conv2d(32, 64, 4, stride=2)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Conv2d(64, 64, 3, stride=1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            layer_init(nn.Linear(64 * 7 * 7, 512)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.actor = layer_init(nn.Linear(512, action_space_n), std=0.01)\n",
    "        self.critic = layer_init(nn.Linear(512, 1), std=1)\n",
    "\n",
    "    def get_value(self, x):\n",
    "        return self.critic(self.network(x / 255.0))\n",
    "        #return self.critic(x)\n",
    "\n",
    "    def get_action_and_value(self, x, action=None):\n",
    "        hidden = self.network(x / 255.0)\n",
    "        #logits = self.actor(x)\n",
    "        logits = self.actor(hidden)\n",
    "        probs = Categorical(logits=logits)\n",
    "        if action is None:\n",
    "            action = probs.sample()\n",
    "        #return action, probs.log_prob(action), probs.entropy(), self.critic(x)\n",
    "        return action, probs.log_prob(action), probs.entropy(), self.critic(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging data\n",
    "# @ray.remote\n",
    "class Logging_Data:\n",
    "    def __init__(self, run_name, args):\n",
    "        self.global_step = 0\n",
    "        if args.track:\n",
    "            import wandb\n",
    "            wandb.init(\n",
    "                project=args.wandb_project_name,\n",
    "                entity=args.wandb_entity,\n",
    "                sync_tensorboard=True,\n",
    "                config=vars(args),\n",
    "                name=run_name,\n",
    "                monitor_gym=True,\n",
    "                save_code=True,\n",
    "                mode=\"offline\"\n",
    "            )\n",
    "        self.writer = SummaryWriter(f\"atari-runs/{run_name}\")\n",
    "        self.writer.add_text(\n",
    "            \"hyperparameters\",\n",
    "            \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in vars(args).items()])),\n",
    "        )\n",
    "\n",
    "    def increment_global_step(self):\n",
    "        self.global_step += 1\n",
    "\n",
    "    def log_data(self, data):\n",
    "        for key, value in data.items():\n",
    "            self.writer.add_scalar(key, value, self.global_step)\n",
    "\n",
    "    def get_global_step(self):\n",
    "        return self.global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rollout\n",
    "# @ray.remote\n",
    "class Rollout:\n",
    "    def __init__(self, env_callable):\n",
    "        # random.seed(env_seed)\n",
    "        # np.random.seed(env_seed)\n",
    "        # torch.manual_seed(env_seed)\n",
    "        # torch.backends.cudnn.deterministic = args.torch_deterministic # not sure what this does\n",
    "        self.env = env_callable()\n",
    "        self.obs = torch.zeros((args.num_steps,) + self.env.observation_space.shape)\n",
    "        self.actions = torch.zeros((args.num_steps,) + self.env.action_space.shape)\n",
    "        self.logprobs = torch.zeros((args.num_steps,))\n",
    "        self.rewards = torch.zeros((args.num_steps,))\n",
    "        self.dones = torch.zeros((args.num_steps,))\n",
    "        self.values = torch.zeros((args.num_steps,))\n",
    "        self.advantages = torch.zeros((args.num_steps,))\n",
    "        self.returns = torch.zeros((args.num_steps,))\n",
    "        \n",
    "        self.next_obs = torch.Tensor(self.env.reset()).to(device)\n",
    "        self.next_done = torch.zeros(1).to(device)\n",
    "\n",
    "        self.episode_return = 0\n",
    "        self.episode_length = 0\n",
    "\n",
    "    def get_env_spaces_data(self):\n",
    "        return self.env.observation_space.shape, self.env.action_space.n\n",
    "        \n",
    "    def rollout(self, agent, logging_data):\n",
    "        for step in range(args.num_steps):\n",
    "            #ray.get(logging_data.increment_global_step.remote())\n",
    "            logging_data.increment_global_step()\n",
    "            self.obs[step] = self.next_obs\n",
    "            self.dones[step] = self.next_done\n",
    "\n",
    "            with torch.no_grad():\n",
    "                action, logprob, _, value = agent.get_action_and_value(torch.unsqueeze(self.next_obs,dim=0))\n",
    "                self.values[step] = value.flatten() # num_envs\n",
    "            self.actions[step] = action\n",
    "            self.logprobs[step] = logprob\n",
    "\n",
    "            self.next_obs, reward, done, info = self.env.step(torch.squeeze(action).cpu().numpy())\n",
    "            self.rewards[step] = torch.tensor(reward).to(device).view(-1) # different\n",
    "            self.next_obs = torch.Tensor(self.next_obs).to(device)\n",
    "            self.next_done = torch.Tensor([done]).to(device) # different\n",
    "            \n",
    "            self.episode_return += reward\n",
    "            self.episode_length += 1\n",
    "\n",
    "            if done:\n",
    "                # global_step = ray.get(logging_data.get_global_step.remote())\n",
    "                global_step = logging_data.get_global_step()\n",
    "                print(f\"global_step={global_step}, episodic_return={self.episode_return}\")\n",
    "                # ray.get(logging_data.log_data.remote(\n",
    "                #     {\"charts/episodic_return\": self.episode_return,\n",
    "                #      \"charts/episodic_length\": self.episode_length}\n",
    "                # ))\n",
    "                logging_data.log_data(\n",
    "                    {\"charts/episodic_return\": self.episode_return,\n",
    "                     \"charts/episodic_length\": self.episode_length}\n",
    "                )\n",
    "                self.episode_length = self.episode_return = 0\n",
    "                self.env.reset()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            #self.next_obs = torch.unsqueeze(self.next_obs, dim=0)\n",
    "            next_value = agent.get_value(torch.unsqueeze(self.next_obs, dim=0)).reshape(1, -1)\n",
    "            lastgaelam = 0\n",
    "            for t in reversed(range(args.num_steps)):\n",
    "                if t == args.num_steps - 1:\n",
    "                    nextnonterminal = 1.0 - self.next_done\n",
    "                    nextvalues = next_value\n",
    "                else:\n",
    "                    nextnonterminal = 1.0 - self.dones[t + 1]\n",
    "                    nextvalues = self.values[t + 1]\n",
    "                delta = self.rewards[t] + args.gamma * nextvalues * nextnonterminal - self.values[t]\n",
    "                self.advantages[t] = lastgaelam = delta + args.gamma * args.gae_lambda * nextnonterminal * lastgaelam\n",
    "            self.returns = self.advantages + self.values \n",
    "\n",
    "        rollout_data = {'obs': self.obs,\n",
    "             'actions': self.actions, \n",
    "             'logprobs': self.logprobs,\n",
    "             'values': self.values,\n",
    "             'returns': self.returns,\n",
    "             'advantages': self.advantages}\n",
    "\n",
    "        return rollout_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(agent, optimizer, rollout_data, args):\n",
    "\n",
    "    b_inds = np.arange(args.batch_size) # indices of batch_size\n",
    "    b_obs = torch.cat([result['obs'] for result in rollout_data], axis=0)\n",
    "    b_logprobs = torch.cat([result['logprobs'] for result in rollout_data], axis=0)\n",
    "    b_actions = torch.cat([result['actions'] for result in rollout_data], axis=0)\n",
    "    b_advantages = torch.cat([result['advantages'] for result in rollout_data], axis=0)\n",
    "    b_returns = torch.cat([result['returns'] for result in rollout_data], axis=0)\n",
    "    b_values = torch.cat([result['values'] for result in rollout_data], axis=0)\n",
    "\n",
    "    clipfracs = []\n",
    "\n",
    "    for epoch in range(args.update_epochs):\n",
    "        np.random.shuffle(b_inds)\n",
    "\n",
    "        for start in range(0, args.batch_size, args.minibatch_size): \n",
    "            end = start + args.minibatch_size \n",
    "            mb_inds = b_inds[start:end] # indices of minibatch\n",
    "\n",
    "            _, newlogprob, entropy, newvalue = agent.get_action_and_value(b_obs[mb_inds], b_actions.long()[mb_inds]) #.long() converts dtype to int64\n",
    "            logratio = newlogprob - b_logprobs[mb_inds] \n",
    "            ratio = logratio.exp() # pi(a|s) / pi_old(a|s); is a tensor of 1s for epoch=0.\n",
    "\n",
    "            with torch.no_grad():\n",
    "                approx_kl = ((ratio - 1) - logratio).mean() # mean of (pi(a|s) / pi_old(a|s) - 1 - log(pi(a|s) / pi_old(a|s)))\n",
    "                clipfracs += [((ratio - 1.0).abs() > args.clip_coef).float().mean().item()]  \n",
    "\n",
    "            mb_advantages = b_advantages[mb_inds]\n",
    "            if args.norm_adv: \n",
    "                mb_advantages = (mb_advantages - mb_advantages.mean()) / (mb_advantages.std() + 1e-8)\n",
    "\n",
    "            # Policy loss\n",
    "            pg_loss1 = -mb_advantages * ratio\n",
    "            pg_loss2 = -mb_advantages * torch.clamp(ratio, 1 - args.clip_coef, 1 + args.clip_coef)\n",
    "            pg_loss = torch.max(pg_loss1, pg_loss2).mean()\n",
    "\n",
    "            # Value loss\n",
    "            newvalue = newvalue.view(-1) # value computed by NN with updated parameters\n",
    "            if args.clip_vloss:\n",
    "                v_loss_unclipped = (newvalue - b_returns[mb_inds]) ** 2\n",
    "                v_clipped = b_values[mb_inds] + torch.clamp(\n",
    "                    newvalue - b_values[mb_inds],\n",
    "                    -args.clip_coef,\n",
    "                    args.clip_coef,\n",
    "                )\n",
    "                v_loss_clipped = (v_clipped - b_returns[mb_inds]) ** 2\n",
    "                v_loss_max = torch.max(v_loss_unclipped, v_loss_clipped)\n",
    "                v_loss = 0.5 * v_loss_max.mean()\n",
    "            else:\n",
    "                v_loss = 0.5 * ((newvalue - b_returns[mb_inds]) ** 2).mean()\n",
    "\n",
    "            entropy_loss = entropy.mean()\n",
    "            loss = pg_loss - args.ent_coef * entropy_loss + v_loss * args.vf_coef\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(agent.parameters(), args.max_grad_norm) # clip gradients before updating them.\n",
    "            optimizer.step()\n",
    "\n",
    "        if args.target_kl is not None:\n",
    "            if approx_kl > args.target_kl:\n",
    "                break\n",
    "\n",
    "    y_pred, y_true = b_values.cpu().numpy(), b_returns.cpu().numpy() \n",
    "    var_y = np.var(y_true)\n",
    "    explained_var = np.nan if var_y == 0 else 1 - np.var(y_true - y_pred) / var_y\n",
    "\n",
    "    output = {\"pg_loss\": pg_loss.item(), \"v_loss\": v_loss.item(), \"entropy_loss\": entropy_loss.item(), \n",
    "              \"approx_kl\": approx_kl, \"explained_var\": explained_var, \"clipfrac\": np.mean(clipfracs)}\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.7.4+069f8bd)\n",
      "[Powered by Stella]\n",
      "/Users/alishehper/work/RL-algorithms/env/lib/python3.9/site-packages/gym/utils/seeding.py:138: DeprecationWarning: \u001b[33mWARN: Function `hash_seed(seed, max_bytes)` is marked as deprecated and will be removed in the future. \u001b[0m\n",
      "  deprecation(\n",
      "/Users/alishehper/work/RL-algorithms/env/lib/python3.9/site-packages/gym/utils/seeding.py:175: DeprecationWarning: \u001b[33mWARN: Function `_bigint_from_bytes(bytes)` is marked as deprecated and will be removed in the future. \u001b[0m\n",
      "  deprecation(\n",
      "/Users/alishehper/work/RL-algorithms/env/lib/python3.9/site-packages/gym/utils/seeding.py:47: DeprecationWarning: \u001b[33mWARN: Function `rng.randint(low, [high, size, dtype])` is marked as deprecated and will be removed in the future. Please use `rng.integers(low, [high, size, dtype])` instead.\u001b[0m\n",
      "  deprecation(\n",
      "/var/folders/y9/jvgs77td31d56hz9y0s_yj7r0000gn/T/ipykernel_51101/3384138287.py:19: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  self.next_obs = torch.Tensor(self.env.reset()).to(device)\n",
      "[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step=23, episodic_return=0.0\n",
      "global_step=46, episodic_return=0.0\n",
      "global_step=69, episodic_return=0.0\n",
      "global_step=92, episodic_return=0.0\n",
      "global_step=115, episodic_return=0.0\n",
      "global_step=151, episodic_return=0.0\n",
      "global_step=174, episodic_return=0.0\n",
      "global_step=197, episodic_return=0.0\n",
      "global_step=218, episodic_return=0.0\n",
      "global_step=241, episodic_return=0.0\n",
      "global_step=354, episodic_return=2.0\n",
      "global_step=377, episodic_return=0.0\n",
      "global_step=407, episodic_return=0.0\n",
      "global_step=430, episodic_return=0.0\n",
      "global_step=453, episodic_return=0.0\n",
      "global_step=476, episodic_return=0.0\n",
      "global_step=499, episodic_return=0.0\n",
      "global_step=610, episodic_return=2.0\n",
      "global_step=663, episodic_return=0.0\n",
      "global_step=686, episodic_return=0.0\n",
      "global_step=709, episodic_return=0.0\n",
      "global_step=732, episodic_return=0.0\n",
      "global_step=755, episodic_return=0.0\n",
      "global_step=866, episodic_return=2.0\n",
      "global_step=887, episodic_return=0.0\n",
      "global_step=919, episodic_return=0.0\n",
      "global_step=942, episodic_return=0.0\n",
      "global_step=994, episodic_return=1.0\n",
      "global_step=1015, episodic_return=0.0\n",
      "update:  1  SPS:  84\n",
      "global_step=1034, episodic_return=0.0\n",
      "global_step=1130, episodic_return=2.0\n",
      "global_step=1151, episodic_return=0.0\n",
      "global_step=1160, episodic_return=0.0\n",
      "global_step=1183, episodic_return=0.0\n",
      "global_step=1250, episodic_return=1.0\n",
      "global_step=1273, episodic_return=0.0\n",
      "global_step=1296, episodic_return=0.0\n",
      "global_step=1367, episodic_return=1.0\n",
      "global_step=1464, episodic_return=1.0\n",
      "global_step=1487, episodic_return=0.0\n",
      "global_step=1536, episodic_return=1.0\n",
      "global_step=1720, episodic_return=1.0\n",
      "global_step=1804, episodic_return=0.0\n",
      "global_step=1875, episodic_return=1.0\n",
      "global_step=1934, episodic_return=0.0\n",
      "global_step=1957, episodic_return=0.0\n",
      "global_step=1978, episodic_return=0.0\n",
      "global_step=2001, episodic_return=0.0\n",
      "global_step=2024, episodic_return=0.0\n",
      "global_step=2047, episodic_return=0.0\n",
      "update:  2  SPS:  86\n",
      "global_step=2070, episodic_return=0.0\n",
      "global_step=2093, episodic_return=0.0\n",
      "global_step=2116, episodic_return=0.0\n",
      "global_step=2139, episodic_return=0.0\n",
      "global_step=2162, episodic_return=0.0\n",
      "global_step=2192, episodic_return=0.0\n",
      "global_step=2215, episodic_return=0.0\n",
      "global_step=2238, episodic_return=0.0\n",
      "global_step=2261, episodic_return=0.0\n",
      "global_step=2284, episodic_return=0.0\n",
      "global_step=2335, episodic_return=1.0\n",
      "global_step=2358, episodic_return=0.0\n",
      "global_step=2429, episodic_return=1.0\n",
      "global_step=2596, episodic_return=4.0\n",
      "global_step=2671, episodic_return=1.0\n",
      "global_step=2689, episodic_return=1.0\n",
      "global_step=2712, episodic_return=0.0\n",
      "global_step=2735, episodic_return=0.0\n",
      "global_step=2758, episodic_return=0.0\n",
      "global_step=2781, episodic_return=0.0\n",
      "global_step=2804, episodic_return=0.0\n",
      "global_step=2892, episodic_return=2.0\n",
      "global_step=2966, episodic_return=0.0\n",
      "global_step=3062, episodic_return=2.0\n",
      "update:  3  SPS:  86\n",
      "global_step=3127, episodic_return=1.0\n",
      "global_step=3150, episodic_return=0.0\n",
      "global_step=3201, episodic_return=0.0\n",
      "global_step=3270, episodic_return=1.0\n",
      "global_step=3293, episodic_return=0.0\n",
      "global_step=3314, episodic_return=0.0\n",
      "global_step=3348, episodic_return=0.0\n",
      "global_step=3371, episodic_return=0.0\n",
      "global_step=3394, episodic_return=0.0\n",
      "global_step=3417, episodic_return=0.0\n",
      "global_step=3440, episodic_return=0.0\n",
      "global_step=3516, episodic_return=4.0\n",
      "global_step=3641, episodic_return=1.0\n",
      "global_step=3767, episodic_return=1.0\n",
      "global_step=3790, episodic_return=0.0\n",
      "global_step=3813, episodic_return=0.0\n",
      "global_step=3836, episodic_return=0.0\n",
      "global_step=3857, episodic_return=1.0\n",
      "global_step=3880, episodic_return=0.0\n",
      "global_step=3903, episodic_return=0.0\n",
      "global_step=3926, episodic_return=0.0\n",
      "global_step=3949, episodic_return=0.0\n",
      "global_step=3981, episodic_return=0.0\n",
      "global_step=4050, episodic_return=1.0\n",
      "global_step=4073, episodic_return=0.0\n",
      "global_step=4096, episodic_return=0.0\n",
      "update:  4  SPS:  86\n",
      "global_step=4144, episodic_return=2.0\n",
      "global_step=4165, episodic_return=0.0\n",
      "global_step=4188, episodic_return=0.0\n",
      "global_step=4211, episodic_return=0.0\n",
      "global_step=4233, episodic_return=0.0\n",
      "global_step=4256, episodic_return=0.0\n",
      "global_step=4359, episodic_return=0.0\n",
      "global_step=4382, episodic_return=0.0\n",
      "global_step=4405, episodic_return=0.0\n",
      "global_step=4428, episodic_return=0.0\n",
      "global_step=4451, episodic_return=0.0\n",
      "global_step=4474, episodic_return=0.0\n",
      "global_step=4487, episodic_return=1.0\n",
      "global_step=4510, episodic_return=0.0\n",
      "global_step=4531, episodic_return=0.0\n",
      "global_step=4552, episodic_return=0.0\n",
      "global_step=4605, episodic_return=1.0\n",
      "global_step=4614, episodic_return=1.0\n",
      "global_step=4683, episodic_return=1.0\n",
      "global_step=4706, episodic_return=0.0\n",
      "global_step=4729, episodic_return=0.0\n",
      "global_step=4755, episodic_return=0.0\n",
      "global_step=4778, episodic_return=0.0\n",
      "global_step=4801, episodic_return=0.0\n",
      "global_step=4966, episodic_return=2.0\n",
      "global_step=4987, episodic_return=0.0\n",
      "global_step=5064, episodic_return=1.0\n",
      "global_step=5115, episodic_return=1.0\n",
      "update:  5  SPS:  87\n",
      "global_step=5130, episodic_return=0.0\n",
      "global_step=5181, episodic_return=1.0\n",
      "global_step=5204, episodic_return=0.0\n",
      "global_step=5227, episodic_return=0.0\n",
      "global_step=5250, episodic_return=2.0\n",
      "global_step=5271, episodic_return=0.0\n",
      "global_step=5294, episodic_return=0.0\n",
      "global_step=5317, episodic_return=0.0\n",
      "global_step=5340, episodic_return=0.0\n",
      "global_step=5393, episodic_return=0.0\n",
      "global_step=5416, episodic_return=0.0\n",
      "global_step=5468, episodic_return=1.0\n",
      "global_step=5524, episodic_return=0.0\n",
      "global_step=5547, episodic_return=0.0\n",
      "global_step=5570, episodic_return=0.0\n",
      "global_step=5593, episodic_return=0.0\n",
      "global_step=5616, episodic_return=0.0\n",
      "global_step=5648, episodic_return=0.0\n",
      "global_step=5720, episodic_return=1.0\n",
      "global_step=5743, episodic_return=0.0\n",
      "global_step=5767, episodic_return=1.0\n",
      "global_step=5790, episodic_return=0.0\n",
      "global_step=5811, episodic_return=0.0\n",
      "global_step=5834, episodic_return=0.0\n",
      "global_step=5855, episodic_return=0.0\n",
      "global_step=5876, episodic_return=0.0\n",
      "global_step=5904, episodic_return=0.0\n",
      "global_step=5973, episodic_return=1.0\n",
      "global_step=6034, episodic_return=0.0\n",
      "global_step=6057, episodic_return=0.0\n",
      "global_step=6080, episodic_return=0.0\n",
      "global_step=6103, episodic_return=0.0\n",
      "global_step=6126, episodic_return=0.0\n",
      "update:  6  SPS:  87\n",
      "global_step=6221, episodic_return=2.0\n",
      "global_step=6272, episodic_return=1.0\n",
      "global_step=6287, episodic_return=1.0\n",
      "global_step=6385, episodic_return=2.0\n",
      "global_step=6415, episodic_return=1.0\n",
      "global_step=6438, episodic_return=0.0\n",
      "global_step=6461, episodic_return=0.0\n",
      "global_step=6482, episodic_return=0.0\n",
      "global_step=6505, episodic_return=0.0\n",
      "global_step=6526, episodic_return=0.0\n",
      "global_step=6535, episodic_return=0.0\n",
      "global_step=6633, episodic_return=2.0\n",
      "global_step=6708, episodic_return=1.0\n",
      "global_step=6731, episodic_return=0.0\n",
      "global_step=6754, episodic_return=0.0\n",
      "global_step=6775, episodic_return=0.0\n",
      "global_step=6795, episodic_return=0.0\n",
      "global_step=6818, episodic_return=0.0\n",
      "global_step=6841, episodic_return=0.0\n",
      "global_step=6864, episodic_return=0.0\n",
      "global_step=6887, episodic_return=0.0\n",
      "global_step=6910, episodic_return=0.0\n",
      "global_step=6941, episodic_return=1.0\n",
      "global_step=6964, episodic_return=0.0\n",
      "global_step=6987, episodic_return=0.0\n",
      "global_step=7010, episodic_return=0.0\n",
      "global_step=7045, episodic_return=0.0\n",
      "global_step=7066, episodic_return=0.0\n",
      "global_step=7089, episodic_return=0.0\n",
      "global_step=7112, episodic_return=0.0\n",
      "global_step=7135, episodic_return=0.0\n",
      "global_step=7158, episodic_return=0.0\n",
      "update:  7  SPS:  87\n",
      "global_step=7191, episodic_return=0.0\n",
      "global_step=7214, episodic_return=0.0\n",
      "global_step=7399, episodic_return=2.0\n",
      "global_step=7520, episodic_return=2.0\n",
      "global_step=7633, episodic_return=2.0\n",
      "global_step=7654, episodic_return=0.0\n",
      "global_step=7694, episodic_return=0.0\n",
      "global_step=7717, episodic_return=0.0\n",
      "global_step=7740, episodic_return=0.0\n",
      "global_step=7761, episodic_return=0.0\n",
      "global_step=7829, episodic_return=0.0\n",
      "global_step=7852, episodic_return=0.0\n",
      "global_step=7875, episodic_return=0.0\n",
      "global_step=7898, episodic_return=0.0\n",
      "global_step=7921, episodic_return=0.0\n",
      "global_step=7977, episodic_return=1.0\n",
      "global_step=8000, episodic_return=0.0\n",
      "global_step=8023, episodic_return=0.0\n",
      "global_step=8046, episodic_return=0.0\n",
      "global_step=8075, episodic_return=0.0\n",
      "global_step=8098, episodic_return=0.0\n",
      "update:  8  SPS:  87\n",
      "global_step=8208, episodic_return=2.0\n",
      "global_step=8229, episodic_return=0.0\n",
      "global_step=8250, episodic_return=0.0\n",
      "global_step=8273, episodic_return=0.0\n",
      "global_step=8296, episodic_return=0.0\n",
      "global_step=8319, episodic_return=0.0\n",
      "global_step=8367, episodic_return=1.0\n",
      "global_step=8390, episodic_return=0.0\n",
      "global_step=8413, episodic_return=0.0\n",
      "global_step=8436, episodic_return=0.0\n",
      "global_step=8487, episodic_return=1.0\n",
      "global_step=8559, episodic_return=1.0\n",
      "global_step=8621, episodic_return=1.0\n",
      "global_step=8644, episodic_return=0.0\n",
      "global_step=8667, episodic_return=0.0\n",
      "global_step=8726, episodic_return=1.0\n",
      "global_step=8749, episodic_return=0.0\n",
      "global_step=8772, episodic_return=0.0\n",
      "global_step=8793, episodic_return=0.0\n",
      "global_step=8816, episodic_return=0.0\n",
      "global_step=8840, episodic_return=0.0\n",
      "global_step=8863, episodic_return=0.0\n",
      "global_step=8884, episodic_return=0.0\n",
      "global_step=8907, episodic_return=0.0\n",
      "global_step=8930, episodic_return=0.0\n",
      "global_step=8953, episodic_return=0.0\n",
      "global_step=8963, episodic_return=0.0\n",
      "global_step=8986, episodic_return=0.0\n",
      "global_step=9007, episodic_return=0.0\n",
      "global_step=9030, episodic_return=0.0\n",
      "global_step=9159, episodic_return=3.0\n",
      "global_step=9182, episodic_return=0.0\n",
      "global_step=9203, episodic_return=0.0\n",
      "update:  9  SPS:  87\n",
      "global_step=9238, episodic_return=0.0\n",
      "global_step=9336, episodic_return=2.0\n",
      "global_step=9355, episodic_return=0.0\n",
      "global_step=9376, episodic_return=0.0\n",
      "global_step=9399, episodic_return=0.0\n",
      "global_step=9422, episodic_return=0.0\n",
      "global_step=9445, episodic_return=0.0\n",
      "global_step=9468, episodic_return=0.0\n",
      "global_step=9478, episodic_return=0.0\n",
      "global_step=9501, episodic_return=0.0\n",
      "global_step=9572, episodic_return=1.0\n",
      "global_step=9595, episodic_return=0.0\n",
      "global_step=9649, episodic_return=2.0\n",
      "global_step=9672, episodic_return=0.0\n",
      "global_step=9695, episodic_return=0.0\n",
      "global_step=9716, episodic_return=0.0\n",
      "global_step=9735, episodic_return=0.0\n",
      "global_step=9758, episodic_return=0.0\n",
      "global_step=9781, episodic_return=0.0\n",
      "global_step=9804, episodic_return=0.0\n",
      "global_step=9872, episodic_return=0.0\n",
      "global_step=9895, episodic_return=0.0\n",
      "global_step=9945, episodic_return=1.0\n",
      "global_step=9968, episodic_return=0.0\n",
      "global_step=9993, episodic_return=1.0\n",
      "global_step=10016, episodic_return=0.0\n",
      "global_step=10039, episodic_return=0.0\n",
      "global_step=10090, episodic_return=1.0\n",
      "global_step=10122, episodic_return=0.0\n",
      "global_step=10145, episodic_return=0.0\n",
      "global_step=10168, episodic_return=0.0\n",
      "global_step=10191, episodic_return=0.0\n",
      "global_step=10214, episodic_return=0.0\n",
      "global_step=10237, episodic_return=0.0\n",
      "update:  10  SPS:  87\n",
      "global_step=10330, episodic_return=2.0\n",
      "global_step=10387, episodic_return=0.0\n",
      "global_step=10410, episodic_return=0.0\n",
      "global_step=10433, episodic_return=0.0\n",
      "global_step=10456, episodic_return=0.0\n",
      "global_step=10477, episodic_return=0.0\n",
      "global_step=10514, episodic_return=0.0\n",
      "global_step=10537, episodic_return=0.0\n",
      "global_step=10560, episodic_return=0.0\n",
      "global_step=10581, episodic_return=0.0\n",
      "global_step=10604, episodic_return=0.0\n",
      "global_step=10635, episodic_return=0.0\n",
      "global_step=10658, episodic_return=0.0\n",
      "global_step=10681, episodic_return=0.0\n",
      "global_step=10704, episodic_return=0.0\n",
      "global_step=10727, episodic_return=0.0\n",
      "global_step=10750, episodic_return=0.0\n",
      "global_step=10767, episodic_return=1.0\n",
      "global_step=10790, episodic_return=0.0\n",
      "global_step=10813, episodic_return=0.0\n",
      "global_step=10836, episodic_return=0.0\n",
      "global_step=10859, episodic_return=0.0\n",
      "global_step=10887, episodic_return=0.0\n",
      "global_step=10908, episodic_return=0.0\n",
      "global_step=10931, episodic_return=0.0\n",
      "global_step=10952, episodic_return=0.0\n",
      "global_step=10975, episodic_return=0.0\n",
      "global_step=10998, episodic_return=0.0\n",
      "global_step=11009, episodic_return=0.0\n",
      "global_step=11030, episodic_return=0.0\n",
      "global_step=11051, episodic_return=0.0\n",
      "global_step=11074, episodic_return=0.0\n",
      "global_step=11097, episodic_return=0.0\n",
      "global_step=11120, episodic_return=0.0\n",
      "global_step=11156, episodic_return=0.0\n",
      "global_step=11179, episodic_return=0.0\n",
      "global_step=11246, episodic_return=1.0\n",
      "update:  11  SPS:  86\n",
      "global_step=11347, episodic_return=2.0\n",
      "global_step=11469, episodic_return=2.0\n",
      "global_step=11492, episodic_return=0.0\n",
      "global_step=11521, episodic_return=0.0\n",
      "global_step=11544, episodic_return=0.0\n",
      "global_step=11567, episodic_return=0.0\n",
      "global_step=11590, episodic_return=0.0\n",
      "global_step=11611, episodic_return=0.0\n",
      "global_step=11632, episodic_return=0.0\n",
      "global_step=11669, episodic_return=0.0\n",
      "global_step=11692, episodic_return=0.0\n",
      "global_step=11715, episodic_return=0.0\n",
      "global_step=11736, episodic_return=0.0\n",
      "global_step=11759, episodic_return=0.0\n",
      "global_step=11778, episodic_return=0.0\n",
      "global_step=11801, episodic_return=0.0\n",
      "global_step=11899, episodic_return=2.0\n",
      "global_step=11917, episodic_return=0.0\n",
      "global_step=11940, episodic_return=0.0\n",
      "global_step=11963, episodic_return=0.0\n",
      "global_step=12037, episodic_return=0.0\n",
      "global_step=12060, episodic_return=0.0\n",
      "global_step=12083, episodic_return=0.0\n",
      "global_step=12106, episodic_return=0.0\n",
      "global_step=12129, episodic_return=0.0\n",
      "global_step=12152, episodic_return=0.0\n",
      "global_step=12165, episodic_return=0.0\n",
      "global_step=12264, episodic_return=2.0\n",
      "global_step=12287, episodic_return=0.0\n",
      "update:  12  SPS:  86\n",
      "global_step=12318, episodic_return=1.0\n",
      "global_step=12392, episodic_return=1.0\n",
      "global_step=12413, episodic_return=0.0\n",
      "global_step=12457, episodic_return=1.0\n",
      "global_step=12480, episodic_return=0.0\n",
      "global_step=12503, episodic_return=0.0\n",
      "global_step=12524, episodic_return=0.0\n",
      "global_step=12551, episodic_return=0.0\n",
      "global_step=12574, episodic_return=0.0\n",
      "global_step=12597, episodic_return=0.0\n",
      "global_step=12620, episodic_return=0.0\n",
      "global_step=12643, episodic_return=0.0\n",
      "global_step=12666, episodic_return=0.0\n",
      "global_step=12678, episodic_return=0.0\n",
      "global_step=12699, episodic_return=0.0\n",
      "global_step=12722, episodic_return=0.0\n",
      "global_step=12743, episodic_return=0.0\n",
      "global_step=12766, episodic_return=0.0\n",
      "global_step=12789, episodic_return=0.0\n",
      "global_step=12866, episodic_return=1.0\n",
      "global_step=12975, episodic_return=2.0\n",
      "global_step=12998, episodic_return=0.0\n",
      "global_step=13021, episodic_return=0.0\n",
      "global_step=13044, episodic_return=0.0\n",
      "global_step=13071, episodic_return=0.0\n",
      "global_step=13094, episodic_return=0.0\n",
      "global_step=13115, episodic_return=0.0\n",
      "global_step=13138, episodic_return=0.0\n",
      "global_step=13161, episodic_return=0.0\n",
      "global_step=13184, episodic_return=0.0\n",
      "global_step=13206, episodic_return=0.0\n",
      "global_step=13229, episodic_return=0.0\n",
      "global_step=13252, episodic_return=0.0\n",
      "global_step=13273, episodic_return=0.0\n",
      "global_step=13296, episodic_return=0.0\n",
      "update:  13  SPS:  86\n",
      "global_step=13332, episodic_return=0.0\n",
      "global_step=13355, episodic_return=0.0\n",
      "global_step=13378, episodic_return=0.0\n",
      "global_step=13401, episodic_return=0.0\n",
      "global_step=13424, episodic_return=0.0\n",
      "global_step=13443, episodic_return=0.0\n",
      "global_step=13583, episodic_return=0.0\n",
      "global_step=13606, episodic_return=0.0\n",
      "global_step=13629, episodic_return=0.0\n",
      "global_step=13652, episodic_return=0.0\n",
      "global_step=13708, episodic_return=0.0\n",
      "global_step=13731, episodic_return=0.0\n",
      "global_step=13752, episodic_return=0.0\n",
      "global_step=13775, episodic_return=0.0\n",
      "global_step=13798, episodic_return=0.0\n",
      "global_step=13834, episodic_return=1.0\n",
      "global_step=13908, episodic_return=1.0\n",
      "global_step=13961, episodic_return=0.0\n",
      "global_step=14059, episodic_return=2.0\n",
      "global_step=14103, episodic_return=0.0\n",
      "global_step=14124, episodic_return=0.0\n",
      "global_step=14215, episodic_return=0.0\n",
      "global_step=14236, episodic_return=0.0\n",
      "global_step=14259, episodic_return=0.0\n",
      "global_step=14280, episodic_return=0.0\n",
      "global_step=14303, episodic_return=0.0\n",
      "update:  14  SPS:  86\n",
      "global_step=14343, episodic_return=0.0\n",
      "global_step=14366, episodic_return=0.0\n",
      "global_step=14415, episodic_return=1.0\n",
      "global_step=14438, episodic_return=0.0\n",
      "global_step=14461, episodic_return=0.0\n",
      "global_step=14526, episodic_return=4.0\n",
      "global_step=14646, episodic_return=2.0\n",
      "global_step=14717, episodic_return=1.0\n",
      "global_step=14761, episodic_return=1.0\n",
      "global_step=14879, episodic_return=1.0\n",
      "global_step=14902, episodic_return=0.0\n",
      "global_step=14925, episodic_return=0.0\n",
      "global_step=14948, episodic_return=0.0\n",
      "global_step=14971, episodic_return=0.0\n",
      "global_step=15026, episodic_return=1.0\n",
      "global_step=15098, episodic_return=1.0\n",
      "global_step=15118, episodic_return=2.0\n",
      "global_step=15139, episodic_return=0.0\n",
      "global_step=15210, episodic_return=1.0\n",
      "global_step=15295, episodic_return=2.0\n",
      "global_step=15318, episodic_return=0.0\n",
      "global_step=15341, episodic_return=0.0\n",
      "update:  15  SPS:  86\n",
      "global_step=15380, episodic_return=0.0\n",
      "global_step=15403, episodic_return=0.0\n",
      "global_step=15426, episodic_return=0.0\n",
      "global_step=15449, episodic_return=0.0\n",
      "global_step=15472, episodic_return=0.0\n",
      "global_step=15494, episodic_return=1.0\n",
      "global_step=15515, episodic_return=0.0\n",
      "global_step=15590, episodic_return=1.0\n",
      "global_step=15685, episodic_return=1.0\n",
      "global_step=15755, episodic_return=2.0\n",
      "global_step=15890, episodic_return=0.0\n",
      "global_step=15913, episodic_return=0.0\n",
      "global_step=15934, episodic_return=0.0\n",
      "global_step=15957, episodic_return=0.0\n",
      "global_step=15980, episodic_return=0.0\n",
      "global_step=16015, episodic_return=0.0\n",
      "global_step=16089, episodic_return=1.0\n",
      "global_step=16112, episodic_return=0.0\n",
      "global_step=16178, episodic_return=1.0\n",
      "global_step=16200, episodic_return=0.0\n",
      "global_step=16223, episodic_return=0.0\n",
      "global_step=16246, episodic_return=0.0\n",
      "global_step=16260, episodic_return=0.0\n",
      "global_step=16283, episodic_return=0.0\n",
      "global_step=16306, episodic_return=0.0\n",
      "global_step=16329, episodic_return=0.0\n",
      "global_step=16352, episodic_return=0.0\n",
      "global_step=16375, episodic_return=0.0\n",
      "update:  16  SPS:  86\n",
      "global_step=16391, episodic_return=0.0\n",
      "global_step=16489, episodic_return=2.0\n",
      "global_step=16510, episodic_return=0.0\n",
      "global_step=16560, episodic_return=1.0\n",
      "global_step=16583, episodic_return=0.0\n",
      "global_step=16604, episodic_return=0.0\n",
      "global_step=16625, episodic_return=0.0\n",
      "global_step=16655, episodic_return=1.0\n",
      "global_step=16730, episodic_return=1.0\n",
      "global_step=16753, episodic_return=0.0\n",
      "global_step=16820, episodic_return=3.0\n",
      "global_step=16843, episodic_return=0.0\n",
      "global_step=16866, episodic_return=0.0\n",
      "global_step=16889, episodic_return=0.0\n",
      "global_step=16899, episodic_return=0.0\n",
      "global_step=16997, episodic_return=2.0\n",
      "global_step=17029, episodic_return=0.0\n",
      "global_step=17150, episodic_return=2.0\n",
      "global_step=17193, episodic_return=1.0\n",
      "global_step=17216, episodic_return=0.0\n",
      "global_step=17239, episodic_return=0.0\n",
      "global_step=17262, episodic_return=0.0\n",
      "global_step=17294, episodic_return=0.0\n",
      "global_step=17315, episodic_return=0.0\n",
      "global_step=17338, episodic_return=0.0\n",
      "global_step=17361, episodic_return=0.0\n",
      "global_step=17382, episodic_return=0.0\n",
      "global_step=17405, episodic_return=0.0\n",
      "update:  17  SPS:  86\n",
      "global_step=17427, episodic_return=0.0\n",
      "global_step=17449, episodic_return=0.0\n",
      "global_step=17500, episodic_return=1.0\n",
      "global_step=17521, episodic_return=0.0\n",
      "global_step=17617, episodic_return=2.0\n",
      "global_step=17640, episodic_return=0.0\n",
      "global_step=17663, episodic_return=0.0\n",
      "global_step=17672, episodic_return=0.0\n",
      "global_step=17695, episodic_return=0.0\n",
      "global_step=17716, episodic_return=0.0\n",
      "global_step=17739, episodic_return=0.0\n",
      "global_step=17762, episodic_return=0.0\n",
      "global_step=17785, episodic_return=0.0\n",
      "global_step=17852, episodic_return=1.0\n",
      "global_step=17875, episodic_return=0.0\n",
      "global_step=17898, episodic_return=0.0\n",
      "global_step=17993, episodic_return=2.0\n",
      "global_step=18014, episodic_return=0.0\n",
      "global_step=18035, episodic_return=0.0\n",
      "global_step=18067, episodic_return=0.0\n",
      "global_step=18139, episodic_return=1.0\n",
      "global_step=18162, episodic_return=0.0\n",
      "global_step=18254, episodic_return=2.0\n",
      "global_step=18277, episodic_return=0.0\n",
      "global_step=18300, episodic_return=0.0\n",
      "global_step=18397, episodic_return=2.0\n",
      "global_step=18418, episodic_return=0.0\n",
      "update:  18  SPS:  86\n",
      "global_step=18517, episodic_return=2.0\n",
      "global_step=18538, episodic_return=0.0\n",
      "global_step=18582, episodic_return=0.0\n",
      "global_step=18605, episodic_return=0.0\n",
      "global_step=18628, episodic_return=0.0\n",
      "global_step=18651, episodic_return=0.0\n",
      "global_step=18674, episodic_return=0.0\n",
      "global_step=18704, episodic_return=0.0\n",
      "global_step=18725, episodic_return=0.0\n",
      "global_step=18793, episodic_return=1.0\n",
      "global_step=18816, episodic_return=0.0\n",
      "global_step=18817, episodic_return=0.0\n",
      "global_step=18840, episodic_return=0.0\n",
      "global_step=18863, episodic_return=0.0\n",
      "global_step=18886, episodic_return=0.0\n",
      "global_step=19003, episodic_return=1.0\n",
      "global_step=19026, episodic_return=0.0\n",
      "global_step=19047, episodic_return=0.0\n",
      "global_step=19070, episodic_return=0.0\n",
      "global_step=19081, episodic_return=0.0\n",
      "global_step=19104, episodic_return=0.0\n",
      "global_step=19125, episodic_return=0.0\n",
      "global_step=19148, episodic_return=0.0\n",
      "global_step=19171, episodic_return=0.0\n",
      "global_step=19192, episodic_return=0.0\n",
      "global_step=19266, episodic_return=1.0\n",
      "global_step=19337, episodic_return=0.0\n",
      "global_step=19407, episodic_return=1.0\n",
      "global_step=19430, episodic_return=0.0\n",
      "global_step=19453, episodic_return=0.0\n",
      "update:  19  SPS:  86\n",
      "global_step=19505, episodic_return=1.0\n",
      "global_step=19528, episodic_return=0.0\n",
      "global_step=19619, episodic_return=1.0\n",
      "global_step=19642, episodic_return=0.0\n",
      "global_step=19663, episodic_return=0.0\n",
      "global_step=19686, episodic_return=0.0\n",
      "global_step=19709, episodic_return=0.0\n",
      "global_step=19735, episodic_return=0.0\n",
      "global_step=19802, episodic_return=1.0\n",
      "global_step=19825, episodic_return=0.0\n",
      "global_step=19851, episodic_return=1.0\n",
      "global_step=19923, episodic_return=1.0\n",
      "global_step=19989, episodic_return=0.0\n",
      "global_step=20010, episodic_return=0.0\n",
      "global_step=20033, episodic_return=0.0\n",
      "global_step=20054, episodic_return=0.0\n",
      "global_step=20075, episodic_return=0.0\n",
      "global_step=20111, episodic_return=0.0\n",
      "global_step=20134, episodic_return=0.0\n",
      "global_step=20157, episodic_return=0.0\n",
      "global_step=20180, episodic_return=0.0\n",
      "global_step=20260, episodic_return=2.0\n",
      "global_step=20283, episodic_return=0.0\n",
      "global_step=20372, episodic_return=0.0\n",
      "global_step=20393, episodic_return=0.0\n",
      "global_step=20416, episodic_return=0.0\n",
      "global_step=20439, episodic_return=0.0\n",
      "global_step=20462, episodic_return=0.0\n",
      "update:  20  SPS:  86\n",
      "global_step=20522, episodic_return=2.0\n",
      "global_step=20593, episodic_return=1.0\n",
      "global_step=20626, episodic_return=0.0\n",
      "global_step=20647, episodic_return=0.0\n",
      "global_step=20670, episodic_return=0.0\n",
      "global_step=20693, episodic_return=0.0\n",
      "global_step=20716, episodic_return=0.0\n",
      "global_step=20890, episodic_return=1.0\n",
      "global_step=20962, episodic_return=1.0\n",
      "global_step=20994, episodic_return=0.0\n",
      "global_step=21017, episodic_return=0.0\n",
      "global_step=21040, episodic_return=0.0\n",
      "global_step=21174, episodic_return=2.0\n",
      "global_step=21245, episodic_return=1.0\n",
      "global_step=21250, episodic_return=1.0\n",
      "global_step=21322, episodic_return=1.0\n",
      "global_step=21379, episodic_return=0.0\n",
      "global_step=21400, episodic_return=0.0\n",
      "global_step=21423, episodic_return=0.0\n",
      "global_step=21446, episodic_return=0.0\n",
      "update:  21  SPS:  86\n",
      "global_step=21561, episodic_return=1.0\n",
      "global_step=21635, episodic_return=0.0\n",
      "global_step=21656, episodic_return=0.0\n",
      "global_step=21679, episodic_return=0.0\n",
      "global_step=21702, episodic_return=0.0\n",
      "global_step=21762, episodic_return=3.0\n",
      "global_step=21785, episodic_return=0.0\n",
      "global_step=21854, episodic_return=1.0\n",
      "global_step=21877, episodic_return=0.0\n",
      "global_step=21932, episodic_return=1.0\n",
      "global_step=21955, episodic_return=0.0\n",
      "global_step=21978, episodic_return=0.0\n",
      "global_step=22001, episodic_return=0.0\n",
      "global_step=22034, episodic_return=2.0\n",
      "global_step=22105, episodic_return=1.0\n",
      "global_step=22128, episodic_return=0.0\n",
      "global_step=22213, episodic_return=1.0\n",
      "global_step=22235, episodic_return=0.0\n",
      "global_step=22292, episodic_return=1.0\n",
      "global_step=22315, episodic_return=0.0\n",
      "global_step=22338, episodic_return=0.0\n",
      "global_step=22361, episodic_return=0.0\n",
      "global_step=22384, episodic_return=0.0\n",
      "global_step=22438, episodic_return=2.0\n",
      "global_step=22459, episodic_return=0.0\n",
      "global_step=22482, episodic_return=0.0\n",
      "global_step=22505, episodic_return=0.0\n",
      "global_step=22528, episodic_return=0.0\n",
      "update:  22  SPS:  86\n",
      "global_step=22531, episodic_return=1.0\n",
      "global_step=22554, episodic_return=0.0\n",
      "global_step=22650, episodic_return=2.0\n",
      "global_step=22696, episodic_return=2.0\n",
      "global_step=22767, episodic_return=1.0\n",
      "global_step=22845, episodic_return=1.0\n",
      "global_step=22918, episodic_return=0.0\n",
      "global_step=22939, episodic_return=0.0\n",
      "global_step=22962, episodic_return=0.0\n",
      "global_step=22985, episodic_return=0.0\n",
      "global_step=23008, episodic_return=0.0\n",
      "global_step=23031, episodic_return=0.0\n",
      "global_step=23047, episodic_return=0.0\n",
      "global_step=23070, episodic_return=0.0\n",
      "global_step=23166, episodic_return=2.0\n",
      "global_step=23200, episodic_return=1.0\n",
      "global_step=23272, episodic_return=1.0\n",
      "global_step=23293, episodic_return=0.0\n",
      "global_step=23303, episodic_return=0.0\n",
      "global_step=23326, episodic_return=0.0\n",
      "global_step=23349, episodic_return=0.0\n",
      "global_step=23445, episodic_return=0.0\n",
      "global_step=23543, episodic_return=2.0\n",
      "update:  23  SPS:  86\n",
      "global_step=23569, episodic_return=0.0\n",
      "global_step=23592, episodic_return=0.0\n",
      "global_step=23615, episodic_return=0.0\n",
      "global_step=23735, episodic_return=1.0\n",
      "global_step=23756, episodic_return=0.0\n",
      "global_step=23812, episodic_return=1.0\n",
      "global_step=23910, episodic_return=2.0\n",
      "global_step=23950, episodic_return=0.0\n",
      "global_step=24048, episodic_return=2.0\n",
      "global_step=24083, episodic_return=0.0\n",
      "global_step=24106, episodic_return=0.0\n",
      "global_step=24129, episodic_return=0.0\n",
      "global_step=24152, episodic_return=0.0\n",
      "global_step=24175, episodic_return=0.0\n",
      "global_step=24289, episodic_return=2.0\n",
      "global_step=24343, episodic_return=2.0\n",
      "global_step=24414, episodic_return=1.0\n",
      "global_step=24436, episodic_return=0.0\n",
      "global_step=24460, episodic_return=0.0\n",
      "global_step=24531, episodic_return=1.0\n",
      "global_step=24554, episodic_return=0.0\n",
      "update:  24  SPS:  86\n",
      "global_step=24609, episodic_return=2.0\n",
      "global_step=24630, episodic_return=0.0\n",
      "global_step=24701, episodic_return=1.0\n",
      "global_step=24726, episodic_return=1.0\n",
      "global_step=24824, episodic_return=2.0\n",
      "global_step=24877, episodic_return=1.0\n",
      "global_step=24949, episodic_return=1.0\n",
      "global_step=24965, episodic_return=0.0\n",
      "global_step=25036, episodic_return=1.0\n",
      "global_step=25057, episodic_return=0.0\n",
      "global_step=25092, episodic_return=0.0\n",
      "global_step=25113, episodic_return=0.0\n",
      "global_step=25136, episodic_return=0.0\n",
      "global_step=25257, episodic_return=1.0\n",
      "global_step=25280, episodic_return=0.0\n",
      "global_step=25303, episodic_return=0.0\n",
      "global_step=25326, episodic_return=0.0\n",
      "global_step=25355, episodic_return=0.0\n",
      "global_step=25378, episodic_return=0.0\n",
      "global_step=25401, episodic_return=0.0\n",
      "global_step=25473, episodic_return=0.0\n",
      "global_step=25494, episodic_return=0.0\n",
      "global_step=25517, episodic_return=0.0\n",
      "global_step=25538, episodic_return=0.0\n",
      "update:  25  SPS:  86\n",
      "global_step=25669, episodic_return=1.0\n",
      "global_step=25691, episodic_return=0.0\n",
      "global_step=25714, episodic_return=0.0\n",
      "global_step=25741, episodic_return=0.0\n",
      "global_step=25812, episodic_return=1.0\n",
      "global_step=25866, episodic_return=0.0\n",
      "global_step=25940, episodic_return=1.0\n",
      "global_step=25963, episodic_return=0.0\n",
      "global_step=26025, episodic_return=1.0\n",
      "global_step=26048, episodic_return=0.0\n",
      "global_step=26069, episodic_return=0.0\n",
      "global_step=26130, episodic_return=2.0\n",
      "global_step=26201, episodic_return=1.0\n",
      "global_step=26245, episodic_return=0.0\n",
      "global_step=26268, episodic_return=0.0\n",
      "global_step=26291, episodic_return=0.0\n",
      "global_step=26314, episodic_return=0.0\n",
      "global_step=26337, episodic_return=0.0\n",
      "global_step=26360, episodic_return=0.0\n",
      "global_step=26393, episodic_return=2.0\n",
      "global_step=26416, episodic_return=0.0\n",
      "global_step=26439, episodic_return=0.0\n",
      "global_step=26532, episodic_return=2.0\n",
      "global_step=26603, episodic_return=1.0\n",
      "global_step=26624, episodic_return=0.0\n",
      "update:  26  SPS:  86\n",
      "global_step=26706, episodic_return=2.0\n",
      "global_step=26729, episodic_return=0.0\n",
      "global_step=26780, episodic_return=1.0\n",
      "global_step=26802, episodic_return=0.0\n",
      "global_step=26825, episodic_return=0.0\n",
      "global_step=26848, episodic_return=0.0\n",
      "global_step=26871, episodic_return=0.0\n",
      "global_step=26882, episodic_return=0.0\n",
      "global_step=26903, episodic_return=0.0\n",
      "global_step=26999, episodic_return=2.0\n",
      "global_step=27061, episodic_return=2.0\n",
      "global_step=27084, episodic_return=0.0\n",
      "global_step=27105, episodic_return=0.0\n",
      "global_step=27128, episodic_return=0.0\n",
      "global_step=27169, episodic_return=1.0\n",
      "global_step=27190, episodic_return=0.0\n",
      "global_step=27264, episodic_return=1.0\n",
      "global_step=27279, episodic_return=0.0\n",
      "global_step=27302, episodic_return=0.0\n",
      "global_step=27323, episodic_return=0.0\n",
      "global_step=27346, episodic_return=0.0\n",
      "global_step=27367, episodic_return=0.0\n",
      "global_step=27390, episodic_return=0.0\n",
      "global_step=27431, episodic_return=2.0\n",
      "global_step=27452, episodic_return=0.0\n",
      "global_step=27475, episodic_return=0.0\n",
      "global_step=27498, episodic_return=0.0\n",
      "global_step=27592, episodic_return=1.0\n",
      "update:  27  SPS:  86\n",
      "global_step=27694, episodic_return=1.0\n",
      "global_step=27717, episodic_return=0.0\n",
      "global_step=27790, episodic_return=0.0\n",
      "global_step=27811, episodic_return=0.0\n",
      "global_step=27834, episodic_return=0.0\n",
      "global_step=27901, episodic_return=1.0\n",
      "global_step=27917, episodic_return=0.0\n",
      "global_step=28015, episodic_return=2.0\n",
      "global_step=28047, episodic_return=0.0\n",
      "global_step=28070, episodic_return=0.0\n",
      "global_step=28093, episodic_return=0.0\n",
      "global_step=28114, episodic_return=0.0\n",
      "global_step=28183, episodic_return=0.0\n",
      "global_step=28206, episodic_return=0.0\n",
      "global_step=28227, episodic_return=0.0\n",
      "global_step=28248, episodic_return=0.0\n",
      "global_step=28309, episodic_return=0.0\n",
      "global_step=28332, episodic_return=0.0\n",
      "global_step=28355, episodic_return=0.0\n",
      "global_step=28378, episodic_return=0.0\n",
      "global_step=28401, episodic_return=0.0\n",
      "global_step=28417, episodic_return=0.0\n",
      "global_step=28440, episodic_return=0.0\n",
      "global_step=28463, episodic_return=0.0\n",
      "global_step=28486, episodic_return=0.0\n",
      "global_step=28509, episodic_return=0.0\n",
      "global_step=28532, episodic_return=0.0\n",
      "global_step=28562, episodic_return=1.0\n",
      "global_step=28585, episodic_return=0.0\n",
      "global_step=28608, episodic_return=0.0\n",
      "global_step=28631, episodic_return=0.0\n",
      "global_step=28654, episodic_return=0.0\n",
      "update:  28  SPS:  85\n",
      "global_step=28711, episodic_return=2.0\n",
      "global_step=28782, episodic_return=1.0\n",
      "global_step=28820, episodic_return=0.0\n",
      "global_step=28843, episodic_return=0.0\n",
      "global_step=28866, episodic_return=0.0\n",
      "global_step=28889, episodic_return=0.0\n",
      "global_step=28912, episodic_return=0.0\n",
      "global_step=28982, episodic_return=1.0\n",
      "global_step=29054, episodic_return=1.0\n",
      "global_step=29061, episodic_return=1.0\n",
      "global_step=29161, episodic_return=2.0\n",
      "global_step=29241, episodic_return=2.0\n",
      "global_step=29320, episodic_return=0.0\n",
      "global_step=29343, episodic_return=0.0\n",
      "global_step=29364, episodic_return=0.0\n",
      "global_step=29387, episodic_return=0.0\n",
      "global_step=29410, episodic_return=0.0\n",
      "global_step=29433, episodic_return=0.0\n",
      "global_step=29451, episodic_return=0.0\n",
      "global_step=29474, episodic_return=0.0\n",
      "global_step=29497, episodic_return=0.0\n",
      "global_step=29520, episodic_return=0.0\n",
      "global_step=29573, episodic_return=0.0\n",
      "global_step=29596, episodic_return=0.0\n",
      "global_step=29619, episodic_return=0.0\n",
      "global_step=29642, episodic_return=0.0\n",
      "global_step=29663, episodic_return=0.0\n",
      "global_step=29684, episodic_return=0.0\n",
      "update:  29  SPS:  85\n",
      "global_step=29781, episodic_return=2.0\n",
      "global_step=29831, episodic_return=0.0\n",
      "global_step=29852, episodic_return=0.0\n",
      "global_step=29873, episodic_return=0.0\n",
      "global_step=29971, episodic_return=0.0\n",
      "global_step=30045, episodic_return=1.0\n",
      "global_step=30068, episodic_return=0.0\n",
      "global_step=30128, episodic_return=1.0\n",
      "global_step=30149, episodic_return=0.0\n",
      "global_step=30235, episodic_return=2.0\n",
      "global_step=30306, episodic_return=1.0\n",
      "global_step=30352, episodic_return=0.0\n",
      "global_step=30375, episodic_return=0.0\n",
      "global_step=30398, episodic_return=0.0\n",
      "global_step=30419, episodic_return=0.0\n",
      "global_step=30442, episodic_return=0.0\n",
      "global_step=30514, episodic_return=2.0\n",
      "global_step=30535, episodic_return=0.0\n",
      "global_step=30603, episodic_return=0.0\n",
      "global_step=30626, episodic_return=0.0\n",
      "global_step=30649, episodic_return=0.0\n",
      "global_step=30672, episodic_return=0.0\n",
      "global_step=30695, episodic_return=0.0\n",
      "update:  30  SPS:  85\n",
      "global_step=30749, episodic_return=1.0\n",
      "global_step=30823, episodic_return=1.0\n",
      "global_step=30846, episodic_return=0.0\n",
      "global_step=30867, episodic_return=2.0\n",
      "global_step=30938, episodic_return=1.0\n",
      "global_step=30959, episodic_return=0.0\n",
      "global_step=30987, episodic_return=0.0\n",
      "global_step=31010, episodic_return=0.0\n",
      "global_step=31117, episodic_return=1.0\n",
      "global_step=31140, episodic_return=0.0\n",
      "global_step=31161, episodic_return=0.0\n",
      "global_step=31184, episodic_return=0.0\n",
      "global_step=31207, episodic_return=0.0\n",
      "global_step=31230, episodic_return=0.0\n",
      "global_step=31274, episodic_return=1.0\n",
      "global_step=31348, episodic_return=1.0\n",
      "global_step=31361, episodic_return=0.0\n",
      "global_step=31382, episodic_return=0.0\n",
      "global_step=31405, episodic_return=0.0\n",
      "global_step=31428, episodic_return=0.0\n",
      "global_step=31502, episodic_return=1.0\n",
      "global_step=31574, episodic_return=1.0\n",
      "global_step=31689, episodic_return=2.0\n",
      "update:  31  SPS:  85\n",
      "global_step=31765, episodic_return=0.0\n",
      "global_step=31788, episodic_return=0.0\n",
      "global_step=31811, episodic_return=0.0\n",
      "global_step=31832, episodic_return=0.0\n",
      "global_step=31927, episodic_return=1.0\n",
      "global_step=31949, episodic_return=0.0\n",
      "global_step=31972, episodic_return=0.0\n",
      "global_step=32002, episodic_return=2.0\n",
      "global_step=32025, episodic_return=0.0\n",
      "global_step=32048, episodic_return=0.0\n",
      "global_step=32069, episodic_return=0.0\n",
      "global_step=32092, episodic_return=0.0\n",
      "global_step=32113, episodic_return=0.0\n",
      "global_step=32149, episodic_return=0.0\n",
      "global_step=32245, episodic_return=2.0\n",
      "global_step=32319, episodic_return=1.0\n",
      "global_step=32342, episodic_return=0.0\n",
      "global_step=32365, episodic_return=0.0\n",
      "global_step=32422, episodic_return=2.0\n",
      "global_step=32493, episodic_return=1.0\n",
      "global_step=32544, episodic_return=1.0\n",
      "global_step=32567, episodic_return=0.0\n",
      "global_step=32590, episodic_return=0.0\n",
      "global_step=32613, episodic_return=0.0\n",
      "global_step=32634, episodic_return=0.0\n",
      "global_step=32656, episodic_return=1.0\n",
      "global_step=32728, episodic_return=1.0\n",
      "update:  32  SPS:  85\n",
      "global_step=32826, episodic_return=2.0\n",
      "global_step=32964, episodic_return=2.0\n",
      "global_step=32987, episodic_return=0.0\n",
      "global_step=33010, episodic_return=0.0\n",
      "global_step=33030, episodic_return=0.0\n",
      "global_step=33053, episodic_return=0.0\n",
      "global_step=33076, episodic_return=0.0\n",
      "global_step=33099, episodic_return=0.0\n",
      "global_step=33122, episodic_return=0.0\n",
      "global_step=33145, episodic_return=0.0\n",
      "global_step=33162, episodic_return=0.0\n",
      "global_step=33183, episodic_return=0.0\n",
      "global_step=33206, episodic_return=0.0\n",
      "global_step=33229, episodic_return=0.0\n",
      "global_step=33252, episodic_return=0.0\n",
      "global_step=33273, episodic_return=0.0\n",
      "global_step=33284, episodic_return=0.0\n",
      "global_step=33307, episodic_return=0.0\n",
      "global_step=33330, episodic_return=0.0\n",
      "global_step=33353, episodic_return=0.0\n",
      "global_step=33376, episodic_return=0.0\n",
      "global_step=33397, episodic_return=0.0\n",
      "global_step=33461, episodic_return=1.0\n",
      "global_step=33553, episodic_return=0.0\n",
      "global_step=33576, episodic_return=0.0\n",
      "global_step=33597, episodic_return=0.0\n",
      "global_step=33698, episodic_return=1.0\n",
      "global_step=33719, episodic_return=0.0\n",
      "global_step=33742, episodic_return=0.0\n",
      "global_step=33765, episodic_return=0.0\n",
      "global_step=33786, episodic_return=0.0\n",
      "update:  33  SPS:  85\n",
      "global_step=33793, episodic_return=1.0\n",
      "global_step=33865, episodic_return=1.0\n",
      "global_step=33929, episodic_return=0.0\n",
      "global_step=34027, episodic_return=2.0\n",
      "global_step=34064, episodic_return=0.0\n",
      "global_step=34085, episodic_return=0.0\n",
      "global_step=34192, episodic_return=0.0\n",
      "global_step=34215, episodic_return=0.0\n",
      "global_step=34238, episodic_return=0.0\n",
      "global_step=34259, episodic_return=0.0\n",
      "global_step=34282, episodic_return=0.0\n",
      "global_step=34303, episodic_return=0.0\n",
      "global_step=34316, episodic_return=0.0\n",
      "global_step=34337, episodic_return=0.0\n",
      "global_step=34360, episodic_return=0.0\n",
      "global_step=34383, episodic_return=0.0\n",
      "global_step=34406, episodic_return=0.0\n",
      "global_step=34429, episodic_return=0.0\n",
      "global_step=34459, episodic_return=2.0\n",
      "global_step=34534, episodic_return=1.0\n",
      "global_step=34557, episodic_return=0.0\n",
      "global_step=34589, episodic_return=2.0\n",
      "global_step=34612, episodic_return=0.0\n",
      "global_step=34633, episodic_return=0.0\n",
      "global_step=34703, episodic_return=0.0\n",
      "global_step=34800, episodic_return=2.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m rollout_data \u001b[39m=\u001b[39m [env\u001b[39m.\u001b[39mrollout(agent, logging_data) \u001b[39mfor\u001b[39;00m env \u001b[39min\u001b[39;00m envs]\n\u001b[1;32m     38\u001b[0m \u001b[39m# Updating parameters of neural networks\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m output \u001b[39m=\u001b[39m update_parameters(agent, optimizer, rollout_data, args)\n\u001b[1;32m     40\u001b[0m global_step \u001b[39m=\u001b[39m logging_data\u001b[39m.\u001b[39mget_global_step()\n\u001b[1;32m     41\u001b[0m SPS \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(global_step \u001b[39m/\u001b[39m (time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time))\n",
      "Cell \u001b[0;32mIn[7], line 56\u001b[0m, in \u001b[0;36mupdate_parameters\u001b[0;34m(agent, optimizer, rollout_data, args)\u001b[0m\n\u001b[1;32m     53\u001b[0m loss \u001b[39m=\u001b[39m pg_loss \u001b[39m-\u001b[39m args\u001b[39m.\u001b[39ment_coef \u001b[39m*\u001b[39m entropy_loss \u001b[39m+\u001b[39m v_loss \u001b[39m*\u001b[39m args\u001b[39m.\u001b[39mvf_coef\n\u001b[1;32m     55\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 56\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     57\u001b[0m nn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(agent\u001b[39m.\u001b[39mparameters(), args\u001b[39m.\u001b[39mmax_grad_norm) \u001b[39m# clip gradients before updating them.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/work/RL-algorithms/env/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/work/RL-algorithms/env/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "# run_name = f\"{args.env_id}__{args.exp_name}__{args.seed}__{int(time.time())}\"\n",
    "run_name = f\"{args.env_id}__{args.seed}__{int(time.time())}\"\n",
    "\n",
    "# logging_data = Logging_Data.remote(run_name, args)\n",
    "logging_data = Logging_Data(run_name, args)\n",
    "\n",
    "# TRY NOT TO MODIFY: seeding\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.backends.cudnn.deterministic = args.torch_deterministic\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
    "\n",
    "# envs = [Rollout.remote(make_env(args.env_id, args.seed + i, i, args.capture_video, run_name)) for i in range(args.num_envs)]\n",
    "# _, action_space_n = ray.get(envs[0].get_env_spaces_data.remote())\n",
    "envs = [Rollout(make_env(args.env_id, args.seed + i, i, args.capture_video, run_name)) for i in range(args.num_envs)]\n",
    "_, action_space_n = envs[0].get_env_spaces_data()\n",
    "agent = Agent(action_space_n).to(device)\n",
    "optimizer = optim.Adam(agent.parameters(), lr=args.learning_rate, eps=1e-5)\n",
    "\n",
    "global_step = 0\n",
    "start_time = time.time()\n",
    "num_updates = args.total_timesteps // args.batch_size\n",
    "\n",
    "for update in range(1, num_updates+1):\n",
    "    # Annealing the learning rate if required\n",
    "    if args.anneal_lr:\n",
    "        frac = 1.0 - (update - 1.0) / num_updates\n",
    "        lrnow = frac * args.learning_rate\n",
    "        optimizer.param_groups[0][\"lr\"] = lrnow\n",
    "\n",
    "    # Collecting data through N parallel actors\n",
    "    # rollout_data = ray.get([env.rollout.remote(agent, logging_data) for env in envs])\n",
    "    rollout_data = [env.rollout(agent, logging_data) for env in envs]\n",
    "    \n",
    "    # Updating parameters of neural networks\n",
    "    output = update_parameters(agent, optimizer, rollout_data, args)\n",
    "    global_step = logging_data.get_global_step()\n",
    "    SPS = int(global_step / (time.time() - start_time))\n",
    "\n",
    "    # ray.get(logging_data.log_data.remote(\n",
    "    #             {\"charts/learning_rate\": optimizer.param_groups[0][\"lr\"],\n",
    "    #                 \"losses/value_loss\": output['v_loss'],\n",
    "    #                 \"losses/policy_loss\": output['pg_loss'],\n",
    "    #                 \"losses/entropy\": output['entropy_loss'],\n",
    "    #                 \"losses/approx_kl\": output['approx_kl'],\n",
    "    #                 \"losses/clipfrac\": output['clipfrac'],\n",
    "    #                 \"losses/explained_variance\": output['clipfrac'],\n",
    "    #                 \"charts/SPS\": SPS\n",
    "    #                 }\n",
    "    #         ))\n",
    "    print(\"update: \", update, \" SPS: \", SPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 84, 84])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1,4,84,84)\n",
    "_, _, _, action = agent.get_action_and_value(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 84, 84])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([3]),\n",
       " tensor([-1.3863], grad_fn=<SqueezeBackward1>),\n",
       " tensor([1.3863], grad_fn=<NegBackward0>),\n",
       " tensor([[0.0047]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.get_action_and_value(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
